
# ğŸ­ BERT-Based Sentiment Analysis on IMDb Reviews

This project implements a **context-aware sentiment analysis** system using **BERT (Bidirectional Encoder Representations from Transformers)**. It classifies movie reviews as **positive** or **negative** with strong accuracy by understanding contextual phrases like *"not happy"* or *"wasn't good"* â€” something traditional ML models often fail at.

---

## ğŸš€ What This Project Covers

- âœ… IMDb movie review dataset
- âœ… Pretrained BERT model (`bert-base-uncased`)
- âœ… Tokenization and padding
- âœ… Fine-tuning BERT using HuggingFace `Trainer`
- âœ… Custom input predictions
- âœ… Ready for deployment (Streamlit / web app compatible)

---

## ğŸ“‚ Dataset

- ğŸ“¦ **IMDb** dataset (from [Hugging Face Datasets](https://huggingface.co/datasets/imdb))
- 50,000 reviews â†’ 25,000 training + 25,000 test
- Balanced binary classification: `Positive (1)` / `Negative (0)`

---

## ğŸ§  Technologies Used

| Tool / Library         | Purpose                         |
|------------------------|--------------------------------|
| `transformers`         | Pretrained BERT model + Trainer |
| `datasets`             | IMDb dataset loading             |
| `sklearn`              | Accuracy evaluation              |
| `PyTorch`              | Model backend                    |

---

## ğŸ§ª Sample Predictions

```python
predict_sentiment("I didn't like the movie.")     # â†’ Negative ğŸ˜
predict_sentiment("Absolutely loved the plot!")   # â†’ Positive ğŸ˜Š
predict_sentiment("Not happy with the ending.")   # â†’ Negative ğŸ˜
```

---

## ğŸ“Š Accuracy

- Trained on a **smaller sample (4K train, 1K test)** for fast performance in notebooks
- Accuracy: ~90% on test split (varies slightly by run)

> You can train on the **full 25K dataset** for higher accuracy if needed.

---

## ğŸ›  How to Run

### â–¶ï¸ In Google Colab

1. Upload `BERT_Sentiment_Analysis_IMDb.ipynb` to your Colab
2. Run each cell step-by-step
3. Use the final cell to enter a custom review and get predictions

---

## ğŸŒ Future Improvements

- Add a Streamlit web app for real-time predictions
- Save and deploy model via `Hugging Face Hub` or `Flask API`
- Train on full dataset or use distilled BERT for faster inference

---

## ğŸ§‘â€ğŸ’» Author

**Karishma Danish**  
_BCA Fresher passionate about AI/ML and NLP_  
[LinkedIn](https://linkedin.com/in/karishmadanish) | [GitHub](https://github.com/karishmadanish) | [Email](karishmadanish265@gmail.com)

---

## ğŸ“Œ Keywords

`BERT` Â· `NLP` Â· `Sentiment Analysis` Â· `IMDb Dataset` Â· `Python` Â· `Transformers` Â· `Fine-tuning` Â· `Hugging Face` Â· `Machine Learning`
